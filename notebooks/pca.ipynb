{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.11.6-ukhwpjnwzzzizek3pgr75zkbhxros5fq/lib/python3.11/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import os \n",
    "import glob \n",
    "import sklearn\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "# from dataset import TinyImageNetDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import medmnist\n",
    "from medmnist import DermaMNIST, PathMNIST, BloodMNIST\n",
    "random.seed(42)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"/local/home/abizeul/data/\"\n",
    "data_folder = \"/cluster/project/sachan/callen/data_alice\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Download and load training dataset\n",
    "folder = f'{data_folder}/cifar-10-batches-py'\n",
    "trainset = torchvision.datasets.CIFAR10(root=data_folder, train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=len(trainset), shuffle=False)\n",
    "\n",
    "# Fetch the entire dataset in one go\n",
    "data_iter = iter(trainloader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "# Step 2: Convert the dataset to NumPy arrays\n",
    "images_np = images.numpy()\n",
    "labels_np = labels.numpy()\n",
    "\n",
    "# Reshape the images to (num_samples, height * width * channels)\n",
    "num_samples = images_np.shape[0]\n",
    "original_shape = images_np.shape\n",
    "images_flat = images_np.reshape(num_samples, -1)\n",
    "\n",
    "# Standardize\n",
    "mean, std   = np.mean(images_flat, axis=0), np.std(images_flat, axis=0)\n",
    "images_flat = (images_flat - mean) / std\n",
    "\n",
    "# Step 4: Perform PCA\n",
    "pca = PCA()  # You can adjust the number of components\n",
    "pca.fit(images_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'{folder}/pc_matrix.npy',pca.components_)\n",
    "np.save(f'{folder}/eigenvalues.npy',pca.explained_variance_)\n",
    "np.save(f'{folder}/eigenvalues_ratio.npy',pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at eigenvalue decomposition \n",
    "# looking at eigenvalue decomposition \n",
    "fig = make_subplots(rows=1, cols=3, subplot_titles=(\"Eigenvalues\", \"Percentage explained variance\",\"Cumulative sum of percentages\"))\n",
    "\n",
    "# First plot (left subplot)\n",
    "fig.add_trace(go.Bar(\n",
    "    x=np.arange(len(pca.explained_variance_)), \n",
    "    y=pca.explained_variance_,\n",
    "    marker=dict(color='rgba(58, 71, 80, 0.6)', line=dict(color='rgba(58, 71, 80, 1.0)', width=1.5)),\n",
    "    opacity=0.8\n",
    "), row=1, col=1)\n",
    "\n",
    "# Second plot (right subplot)\n",
    "fig.add_trace(go.Bar(\n",
    "    x=np.arange(len(pca.explained_variance_ratio_)), \n",
    "    y=pca.explained_variance_ratio_,  # Replace with a different dataset or transformation for a different plot\n",
    "    marker=dict(color='rgba(120, 50, 80, 0.6)', line=dict(color='rgba(120, 50, 80, 1.0)', width=1.5)),\n",
    "    opacity=0.8\n",
    "), row=1, col=2)\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=np.arange(len(pca.explained_variance_ratio_)), \n",
    "    y=np.cumsum(pca.explained_variance_ratio_),  # Replace with a different dataset or transformation for a different plot\n",
    "    marker=dict(color='rgba(120, 50, 80, 0.6)', line=dict(color='rgba(120, 50, 80, 1.0)', width=1.5)),\n",
    "    opacity=0.8\n",
    "), row=1, col=3)\n",
    "\n",
    "# Update layout for aesthetics and specify the size\n",
    "fig.update_layout(\n",
    "    title_text='',\n",
    "    xaxis=dict(\n",
    "        title='',\n",
    "        titlefont=dict(size=14),\n",
    "        tickfont=dict(size=12),\n",
    "        showgrid=True,  # Add grid lines for y-axis\n",
    "        gridcolor='lightgrey',  # Color of grid lines\n",
    "        gridwidth=0.5  # Width of grid lines\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='',\n",
    "        titlefont=dict(size=14),\n",
    "        tickfont=dict(size=12),\n",
    "        type='log',\n",
    "        showgrid=True,  # Add grid lines for y-axis\n",
    "        gridcolor='lightgrey',  # Color of grid lines\n",
    "        gridwidth=0.5  # Width of grid lines\n",
    "    ),\n",
    "    plot_bgcolor='white',\n",
    "    showlegend=False,\n",
    "    margin=dict(l=40, r=40, t=40, b=40),\n",
    "    width=1000,  # Specify width of the image\n",
    "    height=600  # Specify height of the image\n",
    ")\n",
    "\n",
    "# Update x-axis and y-axis for the first subplot\n",
    "fig.update_xaxes(title_text='Components', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=1)\n",
    "fig.update_yaxes(title_text='Explained variance (Log Scale)', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 type='log', showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=1)\n",
    "\n",
    "# Update x-axis and y-axis for the second subplot\n",
    "fig.update_xaxes(title_text='Components', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=2)\n",
    "fig.update_yaxes(title_text='Explained variance (Log Scale)', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 type='log', showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=2)\n",
    "\n",
    "# Update x-axis and y-axis for the second subplot\n",
    "fig.update_xaxes(title_text='Components', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=3)\n",
    "fig.update_yaxes(title_text='Explained variance (Log Scale)', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 type='log', showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=3)\n",
    "\n",
    "\n",
    "# Save the figure as a PNG file\n",
    "fig.write_image(f\"{folder}/eigenvalues.png\")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Visualize the result of pc filtering on one image\n",
    "def reconstruct_image(pca, components, mean, std_mean, std_stdev, shape):\n",
    "    image_reconstructed = np.dot(components, pca.components_) + mean\n",
    "    image_reconstructed = (image_reconstructed * std_stdev) + std_mean\n",
    "    image_reconstructed = image_reconstructed.reshape(shape)\n",
    "    return image_reconstructed\n",
    "\n",
    "ratios = [0.1,0.2,0.4,0.6,0.7,0.75,0.8,0.85,0.9,0.95,0.99]\n",
    "nb_plots = len(ratios) + 1\n",
    "nb_plots_row = 6\n",
    "nb_components = min(images_flat.shape[0],images_flat.shape[1])\n",
    "nb_plots_columns = int(np.ceil(nb_plots/nb_plots_row))\n",
    "\n",
    "for j, img in enumerate(images_np[:2]):\n",
    "    print(img.shape)\n",
    "    fig, ax = plt.subplots(nb_plots_columns,nb_plots_row,figsize=(20,5))\n",
    "    ax[0,0].imshow(np.transpose(img, (1,2,0)),cmap=\"gray\")\n",
    "    ax[0,0].set_title(\"Original Image\")\n",
    "    ax[0,0].axis('off')\n",
    "\n",
    "    fig_, ax_ = plt.subplots(nb_plots_columns,nb_plots_row,figsize=(20,5))\n",
    "    ax_[0,0].imshow(np.transpose(img, (1,2,0)),cmap=\"gray\")\n",
    "    ax_[0,0].set_title(\"Original Image\")\n",
    "    ax_[0,0].axis('off')\n",
    "\n",
    "    fig2, ax2 = plt.subplots(nb_plots_columns,nb_plots_row,figsize=(20,5))\n",
    "    ax2[0,0].imshow(np.transpose(img, (1,2,0)),cmap=\"gray\")\n",
    "    ax2[0,0].set_title(\"Original Image\")\n",
    "    ax2[0,0].axis('off')\n",
    "\n",
    "    fig2_, ax2_ = plt.subplots(nb_plots_columns,nb_plots_row,figsize=(20,5))\n",
    "    ax2_[0,0].imshow(np.transpose(img, (1,2,0)),cmap=\"gray\")\n",
    "    ax2_[0,0].set_title(\"Original Image\")\n",
    "    ax2_[0,0].axis('off')\n",
    "\n",
    "    c=pca.transform(images_flat[j:j+1])\n",
    "    cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "    for i, r in enumerate(ratios):\n",
    "        row, column = (i+1)//nb_plots_row, (i+1)%nb_plots_row\n",
    "\n",
    "        final_component = int(r*nb_components)\n",
    "        components = np.zeros_like(c)\n",
    "        components[:, :final_component] = c[:, :final_component]\n",
    "        reconstructed_image = reconstruct_image(pca, components, pca.mean_, mean, std, [1]+list(original_shape[1:]))\n",
    "\n",
    "        ax[row,column].imshow(np.transpose(reconstructed_image[0], (1,2,0)),cmap=\"gray\")\n",
    "        ax[row,column].set_title(f\"ratio {r}\")\n",
    "        ax[row,column].axis('off')\n",
    "        \n",
    "        #######\n",
    "        components = np.zeros_like(c)\n",
    "        final_component = nb_components - final_component\n",
    "        components[:, -final_component:] = c[:, -final_component:]\n",
    "        reconstructed_image = reconstruct_image(pca, components, pca.mean_, mean, std, [1]+list(original_shape[1:]))\n",
    "\n",
    "        ax_[row,column].imshow(np.transpose(reconstructed_image[0], (1,2,0)),cmap=\"gray\")\n",
    "        ax_[row,column].set_title(f\"ratio {round(1-r,2)}\")\n",
    "        ax_[row,column].axis('off')\n",
    "\n",
    "        #######\n",
    "        final_component=int(np.argmin(np.abs(cumsum - r)))+1\n",
    "        components = np.zeros_like(c)\n",
    "        components[:, :final_component] = c[:, :final_component]\n",
    "        reconstructed_image = reconstruct_image(pca, components, pca.mean_, mean, std, [1]+list(original_shape[1:]))\n",
    "\n",
    "        ax2[row,column].imshow(np.transpose(reconstructed_image[0], (1,2,0)),cmap=\"gray\")\n",
    "        ax2[row,column].set_title(f\"ratio {r}\")\n",
    "        ax2[row,column].axis('off')\n",
    "\n",
    "        #######\n",
    "        final_component = nb_components - final_component\n",
    "        components = np.zeros_like(c)\n",
    "        components[:, -final_component:] = c[:, -final_component:]\n",
    "        reconstructed_image = reconstruct_image(pca, components, pca.mean_, mean, std, [1]+list(original_shape[1:]))\n",
    "\n",
    "        ax2_[row,column].imshow(np.transpose(reconstructed_image[0], (1,2,0)),cmap=\"gray\")\n",
    "        ax2_[row,column].set_title(f\"ratio {round(1-r,2)}\")\n",
    "        ax2_[row,column].axis('off')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10 Reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load training dataset\n",
    "percentage_samples=0.2\n",
    "folder = '/local/home/abizeul/data/cifar-10-batches-py'\n",
    "trainset = torchvision.datasets.CIFAR10(root='/local/home/abizeul/data', train=True, download=True, transform=transform)\n",
    "subset_indices = torch.randperm(len(trainset))[:int(percentage_samples*len(trainset))]\n",
    "trainset = Subset(trainset, subset_indices)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=len(trainset), shuffle=False)\n",
    "\n",
    "# Fetch the entire dataset in one go\n",
    "data_iter = iter(trainloader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "# Step 2: Convert the dataset to NumPy arrays\n",
    "images_np = images.numpy()\n",
    "labels_np = labels.numpy()\n",
    "\n",
    "# Reshape the images to (num_samples, height * width * channels)\n",
    "num_samples = images_np.shape[0]\n",
    "original_shape = images_np.shape\n",
    "images_flat = images_np.reshape(num_samples, -1)\n",
    "\n",
    "# Standardize\n",
    "mean, std   = np.mean(images_flat, axis=0), np.std(images_flat, axis=0)\n",
    "images_flat = (images_flat - mean) / std\n",
    "\n",
    "# Step 4: Perform PCA\n",
    "pca = PCA()  # You can adjust the number of components\n",
    "pca.fit(images_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=3, subplot_titles=(\"Eigenvalues\", \"Percentage explained variance\",\"Cumulative sum of percentages\"))\n",
    "\n",
    "# First plot (left subplot)\n",
    "fig.add_trace(go.Bar(\n",
    "    x=np.arange(len(pca.explained_variance_)), \n",
    "    y=pca.explained_variance_,\n",
    "    marker=dict(color='rgba(58, 71, 80, 0.6)', line=dict(color='rgba(58, 71, 80, 1.0)', width=1.5)),\n",
    "    opacity=0.8\n",
    "), row=1, col=1)\n",
    "\n",
    "# Second plot (right subplot)\n",
    "fig.add_trace(go.Bar(\n",
    "    x=np.arange(len(pca.explained_variance_ratio_)), \n",
    "    y=pca.explained_variance_ratio_,  # Replace with a different dataset or transformation for a different plot\n",
    "    marker=dict(color='rgba(120, 50, 80, 0.6)', line=dict(color='rgba(120, 50, 80, 1.0)', width=1.5)),\n",
    "    opacity=0.8\n",
    "), row=1, col=2)\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=np.arange(len(pca.explained_variance_ratio_)), \n",
    "    y=np.cumsum(pca.explained_variance_ratio_),  # Replace with a different dataset or transformation for a different plot\n",
    "    marker=dict(color='rgba(120, 50, 80, 0.6)', line=dict(color='rgba(120, 50, 80, 1.0)', width=1.5)),\n",
    "    opacity=0.8\n",
    "), row=1, col=3)\n",
    "\n",
    "# Update layout for aesthetics and specify the size\n",
    "fig.update_layout(\n",
    "    title_text='',\n",
    "    xaxis=dict(\n",
    "        title='',\n",
    "        titlefont=dict(size=14),\n",
    "        tickfont=dict(size=12),\n",
    "        showgrid=True,  # Add grid lines for y-axis\n",
    "        gridcolor='lightgrey',  # Color of grid lines\n",
    "        gridwidth=0.5  # Width of grid lines\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='',\n",
    "        titlefont=dict(size=14),\n",
    "        tickfont=dict(size=12),\n",
    "        type='log',\n",
    "        showgrid=True,  # Add grid lines for y-axis\n",
    "        gridcolor='lightgrey',  # Color of grid lines\n",
    "        gridwidth=0.5  # Width of grid lines\n",
    "    ),\n",
    "    plot_bgcolor='white',\n",
    "    showlegend=False,\n",
    "    margin=dict(l=40, r=40, t=40, b=40),\n",
    "    width=1000,  # Specify width of the image\n",
    "    height=600  # Specify height of the image\n",
    ")\n",
    "\n",
    "# Update x-axis and y-axis for the first subplot\n",
    "fig.update_xaxes(title_text='Components', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=1)\n",
    "fig.update_yaxes(title_text='Explained variance (Log Scale)', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 type='log', showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=1)\n",
    "\n",
    "# Update x-axis and y-axis for the second subplot\n",
    "fig.update_xaxes(title_text='Components', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=2)\n",
    "fig.update_yaxes(title_text='Explained variance (Log Scale)', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 type='log', showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=2)\n",
    "\n",
    "# Update x-axis and y-axis for the second subplot\n",
    "fig.update_xaxes(title_text='Components', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=3)\n",
    "fig.update_yaxes(title_text='Explained variance (Log Scale)', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 type='log', showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=3)\n",
    "\n",
    "\n",
    "# Save the figure as a PNG file\n",
    "fig.write_image(f\"{folder}/eigenvalues.png\")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Visualize the result of pc filtering on one image\n",
    "def reconstruct_image(pca, components, mean, std_mean, std_stdev, shape):\n",
    "    image_reconstructed = np.dot(components, pca.components_) + mean\n",
    "    image_reconstructed = (image_reconstructed * std_stdev) + std_mean\n",
    "    image_reconstructed = image_reconstructed.reshape(shape)\n",
    "    return image_reconstructed\n",
    "\n",
    "ratios = [0.1,0.2,0.4,0.6,0.7,0.75,0.8,0.85,0.9,0.95,0.99]\n",
    "nb_plots = len(ratios) + 1\n",
    "nb_plots_row = 6\n",
    "nb_components = min(images_flat.shape[0],images_flat.shape[1])\n",
    "nb_plots_columns = int(np.ceil(nb_plots/nb_plots_row))\n",
    "\n",
    "for j, img in enumerate(images_np[:2]):\n",
    "    print(img.shape)\n",
    "    fig, ax = plt.subplots(nb_plots_columns,nb_plots_row,figsize=(20,5))\n",
    "    ax[0,0].imshow(np.transpose(img, (1,2,0)),cmap=\"gray\")\n",
    "    ax[0,0].set_title(\"Original Image\")\n",
    "    ax[0,0].axis('off')\n",
    "\n",
    "    fig_, ax_ = plt.subplots(nb_plots_columns,nb_plots_row,figsize=(20,5))\n",
    "    ax_[0,0].imshow(np.transpose(img, (1,2,0)),cmap=\"gray\")\n",
    "    ax_[0,0].set_title(\"Original Image\")\n",
    "    ax_[0,0].axis('off')\n",
    "\n",
    "    fig2, ax2 = plt.subplots(nb_plots_columns,nb_plots_row,figsize=(20,5))\n",
    "    ax2[0,0].imshow(np.transpose(img, (1,2,0)),cmap=\"gray\")\n",
    "    ax2[0,0].set_title(\"Original Image\")\n",
    "    ax2[0,0].axis('off')\n",
    "\n",
    "    fig2_, ax2_ = plt.subplots(nb_plots_columns,nb_plots_row,figsize=(20,5))\n",
    "    ax2_[0,0].imshow(np.transpose(img, (1,2,0)),cmap=\"gray\")\n",
    "    ax2_[0,0].set_title(\"Original Image\")\n",
    "    ax2_[0,0].axis('off')\n",
    "\n",
    "    c=pca.transform(images_flat[j:j+1])\n",
    "    cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "    for i, r in enumerate(ratios):\n",
    "        row, column = (i+1)//nb_plots_row, (i+1)%nb_plots_row\n",
    "\n",
    "        final_component = int(r*nb_components)\n",
    "        components = np.zeros_like(c)\n",
    "        components[:, :final_component] = c[:, :final_component]\n",
    "        reconstructed_image = reconstruct_image(pca, components, pca.mean_, mean, std, [1]+list(original_shape[1:]))\n",
    "\n",
    "        ax[row,column].imshow(np.transpose(reconstructed_image[0], (1,2,0)),cmap=\"gray\")\n",
    "        ax[row,column].set_title(f\"ratio {r}\")\n",
    "        ax[row,column].axis('off')\n",
    "        \n",
    "        #######\n",
    "        components = np.zeros_like(c)\n",
    "        final_component = nb_components - final_component\n",
    "        components[:, -final_component:] = c[:, -final_component:]\n",
    "        reconstructed_image = reconstruct_image(pca, components, pca.mean_, mean, std, [1]+list(original_shape[1:]))\n",
    "\n",
    "        ax_[row,column].imshow(np.transpose(reconstructed_image[0], (1,2,0)),cmap=\"gray\")\n",
    "        ax_[row,column].set_title(f\"ratio {round(1-r,2)}\")\n",
    "        ax_[row,column].axis('off')\n",
    "\n",
    "        #######\n",
    "        final_component=int(np.argmin(np.abs(cumsum - r)))+1\n",
    "        components = np.zeros_like(c)\n",
    "        components[:, :final_component] = c[:, :final_component]\n",
    "        reconstructed_image = reconstruct_image(pca, components, pca.mean_, mean, std, [1]+list(original_shape[1:]))\n",
    "\n",
    "        ax2[row,column].imshow(np.transpose(reconstructed_image[0], (1,2,0)),cmap=\"gray\")\n",
    "        ax2[row,column].set_title(f\"ratio {r}\")\n",
    "        ax2[row,column].axis('off')\n",
    "\n",
    "        #######\n",
    "        final_component = nb_components - final_component\n",
    "        components = np.zeros_like(c)\n",
    "        components[:, -final_component:] = c[:, -final_component:]\n",
    "        reconstructed_image = reconstruct_image(pca, components, pca.mean_, mean, std, [1]+list(original_shape[1:]))\n",
    "\n",
    "        ax2_[row,column].imshow(np.transpose(reconstructed_image[0], (1,2,0)),cmap=\"gray\")\n",
    "        ax2_[row,column].set_title(f\"ratio {round(1-r,2)}\")\n",
    "        ax2_[row,column].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TinyImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = f'{data_folder}/tiny-imagenet-200'\n",
    "# trainset = torchvision.datasets.ImageFolder(folder, transform=transform)\n",
    "# trainloader =  torch.utils.data.DataLoader(trainset, batch_size=len(trainset), shuffle=False, num_workers=4)\n",
    "\n",
    "# # Fetch the entire dataset in one go\n",
    "# data_iter = iter(trainloader)\n",
    "# images, labels = next(data_iter)\n",
    "\n",
    "# # Step 2: Convert the dataset to NumPy arrays\n",
    "# images_np = images.numpy()\n",
    "# labels_np = labels.numpy()\n",
    "\n",
    "# # Reshape the images to (num_samples, height * width * channels)\n",
    "# num_samples = images_np.shape[0]\n",
    "# original_shape = images_np.shape\n",
    "# images_flat = images_np.reshape(num_samples, -1)\n",
    "\n",
    "# # Standardize\n",
    "# mean, std   = np.mean(images_flat, axis=0), np.std(images_flat, axis=0)\n",
    "# images_flat = (images_flat - mean) / std\n",
    "# nb_components = min(images_flat.shape[0],images_flat.shape[1])\n",
    "\n",
    "# # Step 4: Perform PCA\n",
    "# pca = PCA()  # You can adjust the number of components\n",
    "# pca.fit(images_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save information\n",
    "np.save(f'{folder}/pc_matrix.npy',pca.components_)\n",
    "np.save(f'{folder}/eigenvalues.npy',pca.explained_variance_)\n",
    "np.save(f'{folder}/eigenvalues_ratio.npy',pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at eigenvalue decomposition \n",
    "fig = make_subplots(rows=1, cols=3, subplot_titles=(\"Eigenvalues\", \"Percentage explained variance\",\"Cumulative sum of percentages\"))\n",
    "\n",
    "# First plot (left subplot)\n",
    "fig.add_trace(go.Bar(\n",
    "    x=np.arange(len(pca.explained_variance_)), \n",
    "    y=pca.explained_variance_,\n",
    "    marker=dict(color='rgba(58, 71, 80, 0.6)', line=dict(color='rgba(58, 71, 80, 1.0)', width=1.5)),\n",
    "    opacity=0.8\n",
    "), row=1, col=1)\n",
    "\n",
    "# Second plot (right subplot)\n",
    "fig.add_trace(go.Bar(\n",
    "    x=np.arange(len(pca.explained_variance_ratio_)), \n",
    "    y=pca.explained_variance_ratio_,  # Replace with a different dataset or transformation for a different plot\n",
    "    marker=dict(color='rgba(120, 50, 80, 0.6)', line=dict(color='rgba(120, 50, 80, 1.0)', width=1.5)),\n",
    "    opacity=0.8\n",
    "), row=1, col=2)\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=np.arange(len(pca.explained_variance_ratio_)), \n",
    "    y=np.cumsum(pca.explained_variance_ratio_),  # Replace with a different dataset or transformation for a different plot\n",
    "    marker=dict(color='rgba(120, 50, 80, 0.6)', line=dict(color='rgba(120, 50, 80, 1.0)', width=1.5)),\n",
    "    opacity=0.8\n",
    "), row=1, col=3)\n",
    "\n",
    "# Update layout for aesthetics and specify the size\n",
    "fig.update_layout(\n",
    "    title_text='',\n",
    "    xaxis=dict(\n",
    "        title='',\n",
    "        titlefont=dict(size=14),\n",
    "        tickfont=dict(size=12),\n",
    "        showgrid=True,  # Add grid lines for y-axis\n",
    "        gridcolor='lightgrey',  # Color of grid lines\n",
    "        gridwidth=0.5  # Width of grid lines\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='',\n",
    "        titlefont=dict(size=14),\n",
    "        tickfont=dict(size=12),\n",
    "        type='log',\n",
    "        showgrid=True,  # Add grid lines for y-axis\n",
    "        gridcolor='lightgrey',  # Color of grid lines\n",
    "        gridwidth=0.5  # Width of grid lines\n",
    "    ),\n",
    "    plot_bgcolor='white',\n",
    "    showlegend=False,\n",
    "    margin=dict(l=40, r=40, t=40, b=40),\n",
    "    width=1000,  # Specify width of the image\n",
    "    height=600  # Specify height of the image\n",
    ")\n",
    "\n",
    "# Update x-axis and y-axis for the first subplot\n",
    "fig.update_xaxes(title_text='Components', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=1)\n",
    "fig.update_yaxes(title_text='Explained variance (Log Scale)', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 type='log', showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=1)\n",
    "\n",
    "# Update x-axis and y-axis for the second subplot\n",
    "fig.update_xaxes(title_text='Components', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=2)\n",
    "fig.update_yaxes(title_text='Explained variance (Log Scale)', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 type='log', showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=2)\n",
    "\n",
    "# Update x-axis and y-axis for the second subplot\n",
    "fig.update_xaxes(title_text='Components', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=3)\n",
    "fig.update_yaxes(title_text='Explained variance (Log Scale)', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 type='log', showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=3)\n",
    "\n",
    "\n",
    "# Save the figure as a PNG file\n",
    "fig.write_image(f\"{folder}/eigenvalues.png\")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save information\n",
    "\n",
    "def reconstruct_image(pca, components,std_mean, std_stdev, shape):\n",
    "    image_reconstructed = np.dot(components, pca)\n",
    "    image_reconstructed = (image_reconstructed * std_stdev) + std_mean\n",
    "    image_reconstructed = image_reconstructed.reshape(shape)\n",
    "    return image_reconstructed\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(folder, transform=transform)\n",
    "trainloader =  torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True, num_workers=1)\n",
    "data_iter = iter(trainloader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "c=np.load(f'{folder}/train/pc_matrix.npy')\n",
    "eigenvalues=np.load(f'{folder}/train/eigenvalues.npy')\n",
    "ratio=np.load(f'{folder}/train/eigenvalues_ratio.npy')\n",
    "mean = np.load(f'{folder}/train/mean.npy')\n",
    "std = np.load(f'{folder}/train/std.npy')\n",
    "\n",
    "r_start, r_stop = 0, 0.1\n",
    "start_component = int(r_start*nb_components)\n",
    "final_component = int(r_stop*nb_components)\n",
    "\n",
    "original_shape = images.shape\n",
    "images = images.reshape(images.shape[0],-1)\n",
    "projection = images @ c\n",
    "\n",
    "components = np.zeros_like(c)\n",
    "components[:, :final_component] = projection[:, start_component:final_component]\n",
    "reconstructed_image = reconstruct_image(c, components, mean, std, original_shape)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(2,2,figsize=(20,5))\n",
    "row=0,column=0\n",
    "ax[row,column].imshow(np.transpose(reconstructed_image[0], (1,2,0)),cmap=\"gray\")\n",
    "ax[row,column].set_title(f\"ratio {r}\")\n",
    "ax[row,column].axis('off')\n",
    "fg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Visualize the result of pc filtering on one image\n",
    "def reconstruct_image(pca, components, mean, std_mean, std_stdev, shape):\n",
    "    image_reconstructed = np.dot(components, pca.components_) + mean\n",
    "    image_reconstructed = (image_reconstructed * std_stdev) + std_mean\n",
    "    image_reconstructed = image_reconstructed.reshape(shape)\n",
    "    return image_reconstructed\n",
    "\n",
    "ratios = [0.1,0.2,0.4,0.6,0.7,0.75,0.8,0.85,0.9,0.95,0.99]\n",
    "nb_plots = len(ratios) + 1\n",
    "nb_plots_row = 6\n",
    "nb_components = min(images_flat.shape[0],images_flat.shape[1])\n",
    "nb_plots_columns = int(np.ceil(nb_plots/nb_plots_row))\n",
    "\n",
    "for j, img in enumerate(images_np[:2]):\n",
    "    print(img.shape)\n",
    "    fig, ax = plt.subplots(nb_plots_columns,nb_plots_row,figsize=(20,5))\n",
    "    ax[0,0].imshow(np.transpose(img, (1,2,0)),cmap=\"gray\")\n",
    "    ax[0,0].set_title(\"Original Image\")\n",
    "    ax[0,0].axis('off')\n",
    "\n",
    "    fig_, ax_ = plt.subplots(nb_plots_columns,nb_plots_row,figsize=(20,5))\n",
    "    ax_[0,0].imshow(np.transpose(img, (1,2,0)),cmap=\"gray\")\n",
    "    ax_[0,0].set_title(\"Original Image\")\n",
    "    ax_[0,0].axis('off')\n",
    "\n",
    "    fig2, ax2 = plt.subplots(nb_plots_columns,nb_plots_row,figsize=(20,5))\n",
    "    ax2[0,0].imshow(np.transpose(img, (1,2,0)),cmap=\"gray\")\n",
    "    ax2[0,0].set_title(\"Original Image\")\n",
    "    ax2[0,0].axis('off')\n",
    "\n",
    "    fig2_, ax2_ = plt.subplots(nb_plots_columns,nb_plots_row,figsize=(20,5))\n",
    "    ax2_[0,0].imshow(np.transpose(img, (1,2,0)),cmap=\"gray\")\n",
    "    ax2_[0,0].set_title(\"Original Image\")\n",
    "    ax2_[0,0].axis('off')\n",
    "\n",
    "    c=pca.transform(images_flat[j:j+1])\n",
    "    cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "    for i, r in enumerate(ratios):\n",
    "        row, column = (i+1)//nb_plots_row, (i+1)%nb_plots_row\n",
    "\n",
    "        final_component = int(r*nb_components)\n",
    "        components = np.zeros_like(c)\n",
    "        components[:, :final_component] = c[:, :final_component]\n",
    "        reconstructed_image = reconstruct_image(pca, components, pca.mean_, mean, std, [1]+list(original_shape[1:]))\n",
    "\n",
    "        ax[row,column].imshow(np.transpose(reconstructed_image[0], (1,2,0)),cmap=\"gray\")\n",
    "        ax[row,column].set_title(f\"ratio {r}\")\n",
    "        ax[row,column].axis('off')\n",
    "        \n",
    "        #######\n",
    "        components = np.zeros_like(c)\n",
    "        final_component = nb_components - final_component\n",
    "        components[:, -final_component:] = c[:, -final_component:]\n",
    "        reconstructed_image = reconstruct_image(pca, components, pca.mean_, mean, std, [1]+list(original_shape[1:]))\n",
    "\n",
    "        ax_[row,column].imshow(np.transpose(reconstructed_image[0], (1,2,0)),cmap=\"gray\")\n",
    "        ax_[row,column].set_title(f\"ratio {round(1-r,2)}\")\n",
    "        ax_[row,column].axis('off')\n",
    "\n",
    "        #######\n",
    "        final_component=int(np.argmin(np.abs(cumsum - r)))+1\n",
    "        components = np.zeros_like(c)\n",
    "        components[:, :final_component] = c[:, :final_component]\n",
    "        reconstructed_image = reconstruct_image(pca, components, pca.mean_, mean, std, [1]+list(original_shape[1:]))\n",
    "\n",
    "        ax2[row,column].imshow(np.transpose(reconstructed_image[0], (1,2,0)),cmap=\"gray\")\n",
    "        ax2[row,column].set_title(f\"ratio {r}\")\n",
    "        ax2[row,column].axis('off')\n",
    "\n",
    "        #######\n",
    "        final_component = nb_components - final_component\n",
    "        components = np.zeros_like(c)\n",
    "        components[:, -final_component:] = c[:, -final_component:]\n",
    "        reconstructed_image = reconstruct_image(pca, components, pca.mean_, mean, std, [1]+list(original_shape[1:]))\n",
    "\n",
    "        ax2_[row,column].imshow(np.transpose(reconstructed_image[0], (1,2,0)),cmap=\"gray\")\n",
    "        ax2_[row,column].set_title(f\"ratio {round(1-r,2)}\")\n",
    "        ax2_[row,column].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "for index,img in enumerate(reconstructed_image):\n",
    "    path, _ = trainset.samples[index]\n",
    "    print(path)\n",
    "    save_image(torch.tensor(img),path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving pcs \n",
    "np.save(\"/local/home/abizeul/reconstruction/pca_matrix/tiny_pcs.npy\",pca.components_)\n",
    "np.save(\"/local/home/abizeul/reconstruction/pca_matrix/tiny_pca_mean.npy\",pca.mean_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nb_plots_columns,nb_plots_row, figsize=(20, 10))\n",
    "\n",
    "for i in range(1,final_component,granularity):\n",
    "    \n",
    "    # Optionally, you can inverse transform to see the approximation\n",
    "    components = np.zeros_like(c)\n",
    "    components[:, -i:] = c[:, -i:]\n",
    "    # take only first sample\n",
    "    components = components[:1]\n",
    "    reconstructed_image = reconstruct_image(pca, components, pca.mean_, original_shape[1:])\n",
    "    \n",
    "    # Display the PCA reconstructed image\n",
    "    index = (i)//granularity\n",
    "    ax[index//nb_plots_row,index%nb_plots_row].imshow(np.transpose(reconstructed_image,(1,2,0)),)\n",
    "    ax[index//nb_plots_row,index%nb_plots_row].set_title(f\"{i}\")\n",
    "    ax[index//nb_plots_row,index%nb_plots_row].axis('off')\n",
    "\n",
    "ax[nb_plots_columns-1,nb_plots_row-1].imshow(np.transpose(images_np[0], (1,2,0)),cmap=\"gray\")\n",
    "ax[nb_plots_columns-1,nb_plots_row-1].set_title(\"Original Image\")\n",
    "ax[nb_plots_columns-1,nb_plots_row-1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DermaMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = f'{data_folder}/medmnist'\n",
    "trainset = DermaMNIST(root=folder,split=\"train\",download=True,size=224,transform=transform)\n",
    "trainloader =  torch.utils.data.DataLoader(trainset, batch_size=len(trainset), shuffle=False, num_workers=4)\n",
    "\n",
    "# Fetch the entire dataset in one go\n",
    "data_iter = iter(trainloader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "# Step 2: Convert the dataset to NumPy arrays\n",
    "images_np = images.numpy()\n",
    "labels_np = labels.numpy()\n",
    "\n",
    "# Reshape the images to (num_samples, height * width * channels)\n",
    "num_samples = images_np.shape[0]\n",
    "original_shape = images_np.shape\n",
    "images_flat = images_np.reshape(num_samples, -1)\n",
    "\n",
    "# Standardize\n",
    "mean, std   = np.mean(images_flat, axis=0), np.std(images_flat, axis=0)\n",
    "images_flat = (images_flat - mean) / std\n",
    "\n",
    "# Step 4: Perform PCA\n",
    "pca = PCA()  # You can adjust the number of components\n",
    "pca.fit(images_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save information\n",
    "np.save(f'{folder}/pc_matrix.npy',pca.components_)\n",
    "np.save(f'{folder}/eigenvalues.npy',pca.explained_variance_)\n",
    "np.save(f'{folder}/eigenvalues_ratio.npy',pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at eigenvalue decomposition \n",
    "fig = make_subplots(rows=1, cols=3, subplot_titles=(\"Eigenvalues\", \"Percentage explained variance\",\"Cumulative sum of percentages\"))\n",
    "\n",
    "# First plot (left subplot)\n",
    "fig.add_trace(go.Bar(\n",
    "    x=np.arange(len(pca.explained_variance_)), \n",
    "    y=pca.explained_variance_,\n",
    "    marker=dict(color='rgba(58, 71, 80, 0.6)', line=dict(color='rgba(58, 71, 80, 1.0)', width=1.5)),\n",
    "    opacity=0.8\n",
    "), row=1, col=1)\n",
    "\n",
    "# Second plot (right subplot)\n",
    "fig.add_trace(go.Bar(\n",
    "    x=np.arange(len(pca.explained_variance_ratio_)), \n",
    "    y=pca.explained_variance_ratio_,  # Replace with a different dataset or transformation for a different plot\n",
    "    marker=dict(color='rgba(120, 50, 80, 0.6)', line=dict(color='rgba(120, 50, 80, 1.0)', width=1.5)),\n",
    "    opacity=0.8\n",
    "), row=1, col=2)\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=np.arange(len(pca.explained_variance_ratio_)), \n",
    "    y=np.cumsum(pca.explained_variance_ratio_),  # Replace with a different dataset or transformation for a different plot\n",
    "    marker=dict(color='rgba(120, 50, 80, 0.6)', line=dict(color='rgba(120, 50, 80, 1.0)', width=1.5)),\n",
    "    opacity=0.8\n",
    "), row=1, col=3)\n",
    "\n",
    "# Update layout for aesthetics and specify the size\n",
    "fig.update_layout(\n",
    "    title_text='',\n",
    "    xaxis=dict(\n",
    "        title='',\n",
    "        titlefont=dict(size=14),\n",
    "        tickfont=dict(size=12),\n",
    "        showgrid=True,  # Add grid lines for y-axis\n",
    "        gridcolor='lightgrey',  # Color of grid lines\n",
    "        gridwidth=0.5  # Width of grid lines\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='',\n",
    "        titlefont=dict(size=14),\n",
    "        tickfont=dict(size=12),\n",
    "        type='log',\n",
    "        showgrid=True,  # Add grid lines for y-axis\n",
    "        gridcolor='lightgrey',  # Color of grid lines\n",
    "        gridwidth=0.5  # Width of grid lines\n",
    "    ),\n",
    "    plot_bgcolor='white',\n",
    "    showlegend=False,\n",
    "    margin=dict(l=40, r=40, t=40, b=40),\n",
    "    width=1000,  # Specify width of the image\n",
    "    height=600  # Specify height of the image\n",
    ")\n",
    "\n",
    "# Update x-axis and y-axis for the first subplot\n",
    "fig.update_xaxes(title_text='Components', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=1)\n",
    "fig.update_yaxes(title_text='Explained variance (Log Scale)', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 type='log', showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=1)\n",
    "\n",
    "# Update x-axis and y-axis for the second subplot\n",
    "fig.update_xaxes(title_text='Components', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=2)\n",
    "fig.update_yaxes(title_text='Explained variance (Log Scale)', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 type='log', showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=2)\n",
    "\n",
    "# Update x-axis and y-axis for the second subplot\n",
    "fig.update_xaxes(title_text='Components', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=3)\n",
    "fig.update_yaxes(title_text='Explained variance (Log Scale)', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 type='log', showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=3)\n",
    "\n",
    "\n",
    "# Save the figure as a PNG file\n",
    "fig.write_image(f\"{folder}/eigenvalues.png\")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Visualize the result of pc filtering on one image\n",
    "def reconstruct_image(pca, components, mean, std_mean, std_stdev, shape):\n",
    "    image_reconstructed = np.dot(components, pca.components_) + mean\n",
    "    image_reconstructed = (image_reconstructed * std_stdev) + std_mean\n",
    "    image_reconstructed = image_reconstructed.reshape(shape)\n",
    "    return image_reconstructed\n",
    "\n",
    "ratios = [0.1,0.2,0.4,0.6,0.7,0.75,0.8,0.85,0.9,0.95,0.99]\n",
    "nb_plots = len(ratios) + 1\n",
    "nb_plots_row = 6\n",
    "nb_components = min(images_flat.shape[0],images_flat.shape[1])\n",
    "nb_plots_columns = int(np.ceil(nb_plots/nb_plots_row))\n",
    "\n",
    "for j, img in enumerate(images_np[:2]):\n",
    "    print(img.shape)\n",
    "    fig, ax = plt.subplots(nb_plots_columns,nb_plots_row,figsize=(20,5))\n",
    "    ax[0,0].imshow(np.transpose(img, (1,2,0)),cmap=\"gray\")\n",
    "    ax[0,0].set_title(\"Original Image\")\n",
    "    ax[0,0].axis('off')\n",
    "\n",
    "    fig_, ax_ = plt.subplots(nb_plots_columns,nb_plots_row,figsize=(20,5))\n",
    "    ax_[0,0].imshow(np.transpose(img, (1,2,0)),cmap=\"gray\")\n",
    "    ax_[0,0].set_title(\"Original Image\")\n",
    "    ax_[0,0].axis('off')\n",
    "\n",
    "    fig2, ax2 = plt.subplots(nb_plots_columns,nb_plots_row,figsize=(20,5))\n",
    "    ax2[0,0].imshow(np.transpose(img, (1,2,0)),cmap=\"gray\")\n",
    "    ax2[0,0].set_title(\"Original Image\")\n",
    "    ax2[0,0].axis('off')\n",
    "\n",
    "    fig2_, ax2_ = plt.subplots(nb_plots_columns,nb_plots_row,figsize=(20,5))\n",
    "    ax2_[0,0].imshow(np.transpose(img, (1,2,0)),cmap=\"gray\")\n",
    "    ax2_[0,0].set_title(\"Original Image\")\n",
    "    ax2_[0,0].axis('off')\n",
    "\n",
    "    c=pca.transform(images_flat[j:j+1])\n",
    "    cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "    for i, r in enumerate(ratios):\n",
    "        row, column = (i+1)//nb_plots_row, (i+1)%nb_plots_row\n",
    "\n",
    "        final_component = int(r*nb_components)\n",
    "        components = np.zeros_like(c)\n",
    "        components[:, :final_component] = c[:, :final_component]\n",
    "        reconstructed_image = reconstruct_image(pca, components, pca.mean_, mean, std, [1]+list(original_shape[1:]))\n",
    "\n",
    "        ax[row,column].imshow(np.transpose(reconstructed_image[0], (1,2,0)),cmap=\"gray\")\n",
    "        ax[row,column].set_title(f\"ratio {r}\")\n",
    "        ax[row,column].axis('off')\n",
    "        \n",
    "        #######\n",
    "        components = np.zeros_like(c)\n",
    "        final_component = nb_components - final_component\n",
    "        components[:, -final_component:] = c[:, -final_component:]\n",
    "        reconstructed_image = reconstruct_image(pca, components, pca.mean_, mean, std, [1]+list(original_shape[1:]))\n",
    "\n",
    "        ax_[row,column].imshow(np.transpose(reconstructed_image[0], (1,2,0)),cmap=\"gray\")\n",
    "        ax_[row,column].set_title(f\"ratio {round(1-r,2)}\")\n",
    "        ax_[row,column].axis('off')\n",
    "\n",
    "        #######\n",
    "        final_component=int(np.argmin(np.abs(cumsum - r)))+1\n",
    "        components = np.zeros_like(c)\n",
    "        components[:, :final_component] = c[:, :final_component]\n",
    "        reconstructed_image = reconstruct_image(pca, components, pca.mean_, mean, std, [1]+list(original_shape[1:]))\n",
    "\n",
    "        ax2[row,column].imshow(np.transpose(reconstructed_image[0], (1,2,0)),cmap=\"gray\")\n",
    "        ax2[row,column].set_title(f\"ratio {r}\")\n",
    "        ax2[row,column].axis('off')\n",
    "\n",
    "        #######\n",
    "        final_component = nb_components - final_component\n",
    "        components = np.zeros_like(c)\n",
    "        components[:, -final_component:] = c[:, -final_component:]\n",
    "        reconstructed_image = reconstruct_image(pca, components, pca.mean_, mean, std, [1]+list(original_shape[1:]))\n",
    "\n",
    "        ax2_[row,column].imshow(np.transpose(reconstructed_image[0], (1,2,0)),cmap=\"gray\")\n",
    "        ax2_[row,column].set_title(f\"ratio {round(1-r,2)}\")\n",
    "        ax2_[row,column].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BloodMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = f'{data_folder}/medmnist'\n",
    "trainset = BloodMNIST(root=folder,split=\"train\",download=True,size=224,transform=transform)\n",
    "trainloader =  torch.utils.data.DataLoader(trainset, batch_size=len(trainset), shuffle=False, num_workers=4)\n",
    "\n",
    "# Fetch the entire dataset in one go\n",
    "data_iter = iter(trainloader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "# Step 2: Convert the dataset to NumPy arrays\n",
    "images_np = images.numpy()\n",
    "labels_np = labels.numpy()\n",
    "\n",
    "# Reshape the images to (num_samples, height * width * channels)\n",
    "num_samples = images_np.shape[0]\n",
    "original_shape = images_np.shape\n",
    "images_flat = images_np.reshape(num_samples, -1)\n",
    "\n",
    "# Standardize\n",
    "mean, std   = np.mean(images_flat, axis=0), np.std(images_flat, axis=0)\n",
    "images_flat = (images_flat - mean) / std\n",
    "\n",
    "# Step 4: Perform PCA\n",
    "pca = PCA()  # You can adjust the number of components\n",
    "pca.fit(images_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save information\n",
    "np.save(f'{folder}/pc_matrix.npy',pca.components_)\n",
    "np.save(f'{folder}/eigenvalues.npy',pca.explained_variance_)\n",
    "np.save(f'{folder}/eigenvalues_ratio.npy',pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at eigenvalue decomposition \n",
    "fig = make_subplots(rows=1, cols=3, subplot_titles=(\"Eigenvalues\", \"Percentage explained variance\",\"Cumulative sum of percentages\"))\n",
    "\n",
    "# First plot (left subplot)\n",
    "fig.add_trace(go.Bar(\n",
    "    x=np.arange(len(pca.explained_variance_)), \n",
    "    y=pca.explained_variance_,\n",
    "    marker=dict(color='rgba(58, 71, 80, 0.6)', line=dict(color='rgba(58, 71, 80, 1.0)', width=1.5)),\n",
    "    opacity=0.8\n",
    "), row=1, col=1)\n",
    "\n",
    "# Second plot (right subplot)\n",
    "fig.add_trace(go.Bar(\n",
    "    x=np.arange(len(pca.explained_variance_ratio_)), \n",
    "    y=pca.explained_variance_ratio_,  # Replace with a different dataset or transformation for a different plot\n",
    "    marker=dict(color='rgba(120, 50, 80, 0.6)', line=dict(color='rgba(120, 50, 80, 1.0)', width=1.5)),\n",
    "    opacity=0.8\n",
    "), row=1, col=2)\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=np.arange(len(pca.explained_variance_ratio_)), \n",
    "    y=np.cumsum(pca.explained_variance_ratio_),  # Replace with a different dataset or transformation for a different plot\n",
    "    marker=dict(color='rgba(120, 50, 80, 0.6)', line=dict(color='rgba(120, 50, 80, 1.0)', width=1.5)),\n",
    "    opacity=0.8\n",
    "), row=1, col=3)\n",
    "\n",
    "# Update layout for aesthetics and specify the size\n",
    "fig.update_layout(\n",
    "    title_text='',\n",
    "    xaxis=dict(\n",
    "        title='',\n",
    "        titlefont=dict(size=14),\n",
    "        tickfont=dict(size=12),\n",
    "        showgrid=True,  # Add grid lines for y-axis\n",
    "        gridcolor='lightgrey',  # Color of grid lines\n",
    "        gridwidth=0.5  # Width of grid lines\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='',\n",
    "        titlefont=dict(size=14),\n",
    "        tickfont=dict(size=12),\n",
    "        type='log',\n",
    "        showgrid=True,  # Add grid lines for y-axis\n",
    "        gridcolor='lightgrey',  # Color of grid lines\n",
    "        gridwidth=0.5  # Width of grid lines\n",
    "    ),\n",
    "    plot_bgcolor='white',\n",
    "    showlegend=False,\n",
    "    margin=dict(l=40, r=40, t=40, b=40),\n",
    "    width=1000,  # Specify width of the image\n",
    "    height=600  # Specify height of the image\n",
    ")\n",
    "\n",
    "# Update x-axis and y-axis for the first subplot\n",
    "fig.update_xaxes(title_text='Components', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=1)\n",
    "fig.update_yaxes(title_text='Explained variance (Log Scale)', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 type='log', showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=1)\n",
    "\n",
    "# Update x-axis and y-axis for the second subplot\n",
    "fig.update_xaxes(title_text='Components', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=2)\n",
    "fig.update_yaxes(title_text='Explained variance (Log Scale)', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 type='log', showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=2)\n",
    "\n",
    "# Update x-axis and y-axis for the second subplot\n",
    "fig.update_xaxes(title_text='Components', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=3)\n",
    "fig.update_yaxes(title_text='Explained variance (Log Scale)', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 type='log', showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=3)\n",
    "\n",
    "\n",
    "# Save the figure as a PNG file\n",
    "fig.write_image(f\"{folder}/eigenvalues.png\")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Visualize the result of pc filtering on one image\n",
    "def reconstruct_image(pca, components, mean, std_mean, std_stdev, shape):\n",
    "    image_reconstructed = np.dot(components, pca.components_) + mean\n",
    "    image_reconstructed = (image_reconstructed * std_stdev) + std_mean\n",
    "    image_reconstructed = image_reconstructed.reshape(shape)\n",
    "    return image_reconstructed\n",
    "\n",
    "ratios = [0.1,0.2,0.4,0.6,0.7,0.75,0.8,0.85,0.9,0.95,0.99]\n",
    "nb_plots = len(ratios) + 1\n",
    "nb_plots_row = 6\n",
    "nb_components = min(images_flat.shape[0],images_flat.shape[1])\n",
    "nb_plots_columns = int(np.ceil(nb_plots/nb_plots_row))\n",
    "\n",
    "for j, img in enumerate(images_np[:2]):\n",
    "    print(img.shape)\n",
    "    fig, ax = plt.subplots(nb_plots_columns,nb_plots_row,figsize=(20,5))\n",
    "    ax[0,0].imshow(np.transpose(img, (1,2,0)),cmap=\"gray\")\n",
    "    ax[0,0].set_title(\"Original Image\")\n",
    "    ax[0,0].axis('off')\n",
    "\n",
    "    fig_, ax_ = plt.subplots(nb_plots_columns,nb_plots_row,figsize=(20,5))\n",
    "    ax_[0,0].imshow(np.transpose(img, (1,2,0)),cmap=\"gray\")\n",
    "    ax_[0,0].set_title(\"Original Image\")\n",
    "    ax_[0,0].axis('off')\n",
    "\n",
    "    fig2, ax2 = plt.subplots(nb_plots_columns,nb_plots_row,figsize=(20,5))\n",
    "    ax2[0,0].imshow(np.transpose(img, (1,2,0)),cmap=\"gray\")\n",
    "    ax2[0,0].set_title(\"Original Image\")\n",
    "    ax2[0,0].axis('off')\n",
    "\n",
    "    fig2_, ax2_ = plt.subplots(nb_plots_columns,nb_plots_row,figsize=(20,5))\n",
    "    ax2_[0,0].imshow(np.transpose(img, (1,2,0)),cmap=\"gray\")\n",
    "    ax2_[0,0].set_title(\"Original Image\")\n",
    "    ax2_[0,0].axis('off')\n",
    "\n",
    "    c=pca.transform(images_flat[j:j+1])\n",
    "    cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "    for i, r in enumerate(ratios):\n",
    "        row, column = (i+1)//nb_plots_row, (i+1)%nb_plots_row\n",
    "\n",
    "        final_component = int(r*nb_components)\n",
    "        components = np.zeros_like(c)\n",
    "        components[:, :final_component] = c[:, :final_component]\n",
    "        reconstructed_image = reconstruct_image(pca, components, pca.mean_, mean, std, [1]+list(original_shape[1:]))\n",
    "\n",
    "        ax[row,column].imshow(np.transpose(reconstructed_image[0], (1,2,0)),cmap=\"gray\")\n",
    "        ax[row,column].set_title(f\"ratio {r}\")\n",
    "        ax[row,column].axis('off')\n",
    "        \n",
    "        #######\n",
    "        components = np.zeros_like(c)\n",
    "        final_component = nb_components - final_component\n",
    "        components[:, -final_component:] = c[:, -final_component:]\n",
    "        reconstructed_image = reconstruct_image(pca, components, pca.mean_, mean, std, [1]+list(original_shape[1:]))\n",
    "\n",
    "        ax_[row,column].imshow(np.transpose(reconstructed_image[0], (1,2,0)),cmap=\"gray\")\n",
    "        ax_[row,column].set_title(f\"ratio {round(1-r,2)}\")\n",
    "        ax_[row,column].axis('off')\n",
    "\n",
    "        #######\n",
    "        final_component=int(np.argmin(np.abs(cumsum - r)))+1\n",
    "        components = np.zeros_like(c)\n",
    "        components[:, :final_component] = c[:, :final_component]\n",
    "        reconstructed_image = reconstruct_image(pca, components, pca.mean_, mean, std, [1]+list(original_shape[1:]))\n",
    "\n",
    "        ax2[row,column].imshow(np.transpose(reconstructed_image[0], (1,2,0)),cmap=\"gray\")\n",
    "        ax2[row,column].set_title(f\"ratio {r}\")\n",
    "        ax2[row,column].axis('off')\n",
    "\n",
    "        #######\n",
    "        final_component = nb_components - final_component\n",
    "        components = np.zeros_like(c)\n",
    "        components[:, -final_component:] = c[:, -final_component:]\n",
    "        reconstructed_image = reconstruct_image(pca, components, pca.mean_, mean, std, [1]+list(original_shape[1:]))\n",
    "\n",
    "        ax2_[row,column].imshow(np.transpose(reconstructed_image[0], (1,2,0)),cmap=\"gray\")\n",
    "        ax2_[row,column].set_title(f\"ratio {round(1-r,2)}\")\n",
    "        ax2_[row,column].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PathMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = f'{data_folder}/medmnist'\n",
    "trainset = PathMNIST(root=folder,split=\"train\",download=True,size=224,transform=transform)\n",
    "trainloader =  torch.utils.data.DataLoader(trainset, batch_size=len(trainset), shuffle=False, num_workers=4)\n",
    "\n",
    "# Fetch the entire dataset in one go\n",
    "data_iter = iter(trainloader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "# Step 2: Convert the dataset to NumPy arrays\n",
    "images_np = images.numpy()\n",
    "labels_np = labels.numpy()\n",
    "\n",
    "# Reshape the images to (num_samples, height * width * channels)\n",
    "num_samples = images_np.shape[0]\n",
    "original_shape = images_np.shape\n",
    "images_flat = images_np.reshape(num_samples, -1)\n",
    "\n",
    "# Standardize\n",
    "mean, std   = np.mean(images_flat, axis=0), np.std(images_flat, axis=0)\n",
    "images_flat = (images_flat - mean) / std\n",
    "\n",
    "# Step 4: Perform PCA\n",
    "pca = PCA()  # You can adjust the number of components\n",
    "pca.fit(images_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save information\n",
    "np.save(f'{folder}/pc_matrix.npy',pca.components_)\n",
    "np.save(f'{folder}/eigenvalues.npy',pca.explained_variance_)\n",
    "np.save(f'{folder}/eigenvalues_ratio.npy',pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at eigenvalue decomposition \n",
    "fig = make_subplots(rows=1, cols=3, subplot_titles=(\"Eigenvalues\", \"Percentage explained variance\",\"Cumulative sum of percentages\"))\n",
    "\n",
    "# First plot (left subplot)\n",
    "fig.add_trace(go.Bar(\n",
    "    x=np.arange(len(pca.explained_variance_)), \n",
    "    y=pca.explained_variance_,\n",
    "    marker=dict(color='rgba(58, 71, 80, 0.6)', line=dict(color='rgba(58, 71, 80, 1.0)', width=1.5)),\n",
    "    opacity=0.8\n",
    "), row=1, col=1)\n",
    "\n",
    "# Second plot (right subplot)\n",
    "fig.add_trace(go.Bar(\n",
    "    x=np.arange(len(pca.explained_variance_ratio_)), \n",
    "    y=pca.explained_variance_ratio_,  # Replace with a different dataset or transformation for a different plot\n",
    "    marker=dict(color='rgba(120, 50, 80, 0.6)', line=dict(color='rgba(120, 50, 80, 1.0)', width=1.5)),\n",
    "    opacity=0.8\n",
    "), row=1, col=2)\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=np.arange(len(pca.explained_variance_ratio_)), \n",
    "    y=np.cumsum(pca.explained_variance_ratio_),  # Replace with a different dataset or transformation for a different plot\n",
    "    marker=dict(color='rgba(120, 50, 80, 0.6)', line=dict(color='rgba(120, 50, 80, 1.0)', width=1.5)),\n",
    "    opacity=0.8\n",
    "), row=1, col=3)\n",
    "\n",
    "# Update layout for aesthetics and specify the size\n",
    "fig.update_layout(\n",
    "    title_text='',\n",
    "    xaxis=dict(\n",
    "        title='',\n",
    "        titlefont=dict(size=14),\n",
    "        tickfont=dict(size=12),\n",
    "        showgrid=True,  # Add grid lines for y-axis\n",
    "        gridcolor='lightgrey',  # Color of grid lines\n",
    "        gridwidth=0.5  # Width of grid lines\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='',\n",
    "        titlefont=dict(size=14),\n",
    "        tickfont=dict(size=12),\n",
    "        type='log',\n",
    "        showgrid=True,  # Add grid lines for y-axis\n",
    "        gridcolor='lightgrey',  # Color of grid lines\n",
    "        gridwidth=0.5  # Width of grid lines\n",
    "    ),\n",
    "    plot_bgcolor='white',\n",
    "    showlegend=False,\n",
    "    margin=dict(l=40, r=40, t=40, b=40),\n",
    "    width=1000,  # Specify width of the image\n",
    "    height=600  # Specify height of the image\n",
    ")\n",
    "\n",
    "# Update x-axis and y-axis for the first subplot\n",
    "fig.update_xaxes(title_text='Components', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=1)\n",
    "fig.update_yaxes(title_text='Explained variance (Log Scale)', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 type='log', showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=1)\n",
    "\n",
    "# Update x-axis and y-axis for the second subplot\n",
    "fig.update_xaxes(title_text='Components', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=2)\n",
    "fig.update_yaxes(title_text='Explained variance (Log Scale)', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 type='log', showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=2)\n",
    "\n",
    "# Update x-axis and y-axis for the second subplot\n",
    "fig.update_xaxes(title_text='Components', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=3)\n",
    "fig.update_yaxes(title_text='Explained variance (Log Scale)', title_font=dict(size=14), tickfont=dict(size=12), \n",
    "                 type='log', showgrid=True, gridcolor='lightgrey', gridwidth=0.5, row=1, col=3)\n",
    "\n",
    "\n",
    "# Save the figure as a PNG file\n",
    "fig.write_image(f\"{folder}/eigenvalues.png\")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Visualize the result of pc filtering on one image\n",
    "def reconstruct_image(pca, components, mean, std_mean, std_stdev, shape):\n",
    "    image_reconstructed = np.dot(components, pca.components_) + mean\n",
    "    image_reconstructed = (image_reconstructed * std_stdev) + std_mean\n",
    "    image_reconstructed = image_reconstructed.reshape(shape)\n",
    "    return image_reconstructed\n",
    "\n",
    "ratios = [0.1,0.2,0.4,0.6,0.7,0.75,0.8,0.85,0.9,0.95,0.99]\n",
    "nb_plots = len(ratios) + 1\n",
    "nb_plots_row = 6\n",
    "nb_components = min(images_flat.shape[0],images_flat.shape[1])\n",
    "nb_plots_columns = int(np.ceil(nb_plots/nb_plots_row))\n",
    "\n",
    "for j, img in enumerate(images_np[:2]):\n",
    "    print(img.shape)\n",
    "    fig, ax = plt.subplots(nb_plots_columns,nb_plots_row,figsize=(20,5))\n",
    "    ax[0,0].imshow(np.transpose(img, (1,2,0)),cmap=\"gray\")\n",
    "    ax[0,0].set_title(\"Original Image\")\n",
    "    ax[0,0].axis('off')\n",
    "\n",
    "    fig_, ax_ = plt.subplots(nb_plots_columns,nb_plots_row,figsize=(20,5))\n",
    "    ax_[0,0].imshow(np.transpose(img, (1,2,0)),cmap=\"gray\")\n",
    "    ax_[0,0].set_title(\"Original Image\")\n",
    "    ax_[0,0].axis('off')\n",
    "\n",
    "    fig2, ax2 = plt.subplots(nb_plots_columns,nb_plots_row,figsize=(20,5))\n",
    "    ax2[0,0].imshow(np.transpose(img, (1,2,0)),cmap=\"gray\")\n",
    "    ax2[0,0].set_title(\"Original Image\")\n",
    "    ax2[0,0].axis('off')\n",
    "\n",
    "    fig2_, ax2_ = plt.subplots(nb_plots_columns,nb_plots_row,figsize=(20,5))\n",
    "    ax2_[0,0].imshow(np.transpose(img, (1,2,0)),cmap=\"gray\")\n",
    "    ax2_[0,0].set_title(\"Original Image\")\n",
    "    ax2_[0,0].axis('off')\n",
    "\n",
    "    c=pca.transform(images_flat[j:j+1])\n",
    "    cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "    for i, r in enumerate(ratios):\n",
    "        row, column = (i+1)//nb_plots_row, (i+1)%nb_plots_row\n",
    "\n",
    "        final_component = int(r*nb_components)\n",
    "        components = np.zeros_like(c)\n",
    "        components[:, :final_component] = c[:, :final_component]\n",
    "        reconstructed_image = reconstruct_image(pca, components, pca.mean_, mean, std, [1]+list(original_shape[1:]))\n",
    "\n",
    "        ax[row,column].imshow(np.transpose(reconstructed_image[0], (1,2,0)),cmap=\"gray\")\n",
    "        ax[row,column].set_title(f\"ratio {r}\")\n",
    "        ax[row,column].axis('off')\n",
    "        \n",
    "        #######\n",
    "        components = np.zeros_like(c)\n",
    "        final_component = nb_components - final_component\n",
    "        components[:, -final_component:] = c[:, -final_component:]\n",
    "        reconstructed_image = reconstruct_image(pca, components, pca.mean_, mean, std, [1]+list(original_shape[1:]))\n",
    "\n",
    "        ax_[row,column].imshow(np.transpose(reconstructed_image[0], (1,2,0)),cmap=\"gray\")\n",
    "        ax_[row,column].set_title(f\"ratio {round(1-r,2)}\")\n",
    "        ax_[row,column].axis('off')\n",
    "\n",
    "        #######\n",
    "        final_component=int(np.argmin(np.abs(cumsum - r)))+1\n",
    "        components = np.zeros_like(c)\n",
    "        components[:, :final_component] = c[:, :final_component]\n",
    "        reconstructed_image = reconstruct_image(pca, components, pca.mean_, mean, std, [1]+list(original_shape[1:]))\n",
    "\n",
    "        ax2[row,column].imshow(np.transpose(reconstructed_image[0], (1,2,0)),cmap=\"gray\")\n",
    "        ax2[row,column].set_title(f\"ratio {r}\")\n",
    "        ax2[row,column].axis('off')\n",
    "\n",
    "        #######\n",
    "        final_component = nb_components - final_component\n",
    "        components = np.zeros_like(c)\n",
    "        components[:, -final_component:] = c[:, -final_component:]\n",
    "        reconstructed_image = reconstruct_image(pca, components, pca.mean_, mean, std, [1]+list(original_shape[1:]))\n",
    "\n",
    "        ax2_[row,column].imshow(np.transpose(reconstructed_image[0], (1,2,0)),cmap=\"gray\")\n",
    "        ax2_[row,column].set_title(f\"ratio {round(1-r,2)}\")\n",
    "        ax2_[row,column].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
